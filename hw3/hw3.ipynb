{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Multiclass and Linear Models\n",
    "\n",
    "UIC CS 412, Spring 2021\n",
    "\n",
    "*According to the Academic Integrity Policy of this course, all work submitted for grading must be done individually.  While we encourage you to talk to your peers and learn from them, this interaction must be superficial with regards to all work submitted for grading.  This means you cannot work in teams, you cannot work side-by-side, you cannot submit someone elseâ€™s work (partial or complete) as your own. In particular, note that you are guilty of academic dishonesty if you extend or receive any kind of unauthorized assistance.  Absolutely no transfer of program code between students is permitted (paper or electronic), and you may not solicit code from family, friends, or online forums.  Other examples of academic dishonesty include emailing your program to another student, copying-pasting code from the internet, working in a group on a homework assignment, and allowing a tutor, TA, or another individual to write an answer for you.  Academic dishonesty is unacceptable, and penalties range from failure to expulsion from the university; cases are handled via the official student conduct process described at https://dos.uic.edu/conductforstudents.shtml.* \n",
    "\n",
    "This homework is an individual assignment for all graduate students. Undergraduate students are allowed to work in pairs and submit one homework assignment per pair. There will be no extra credit given to undergraduate students who choose to work alone. The pairs of students who choose to work together and submit one homework assignment together still need to abide by the Academic Integrity Policy and not share or receive help from others (except each other).\n",
    "\n",
    "There are two parts to this project. The first is on multiclass reductions (50%). The second is on linear models and gradient descent (50%). There are also opportunities for extra credit (up to 25%).\n",
    "\n",
    "\n",
    "## Due Date\n",
    "\n",
    "This assignment is due at 11:59pm Thursday, March 11th. \n",
    "\n",
    "### Files You'll Edit\n",
    "\n",
    "``multiclass.py``: The multiclass classification implementation you need to complete.\n",
    "\n",
    "``gd.py``: The gradient descent file you need to edit.\n",
    "\n",
    "``quizbowl.py``: Multiclass evaluation of the quiz bowl dataset (optional).\n",
    "\n",
    "``predictions.txt``: This file is automatically generated as part of Part 3 (optional).\n",
    "\n",
    "### Files you might want to look at\n",
    "  \n",
    "``binary.py``: Our generic interface for binary classifiers (actually\n",
    "works for regression and other types of classification, too).\n",
    "\n",
    "``datasets.py``: Where a handful of test data sets are stored.\n",
    "\n",
    "``util.py``: A handful of useful utility functions: these will\n",
    "undoubtedly be helpful to you, so take a look!\n",
    "\n",
    "``runClassifier.py``: A few wrappers for doing useful things with\n",
    "classifiers, like training them, generating learning curves, etc.\n",
    "\n",
    "``mlGraphics.py``: A few useful plotting commands\n",
    "\n",
    "``data/*``: All of the datasets we'll use.\n",
    "\n",
    "### What to Submit\n",
    "\n",
    "You will hand in all of the python files listed above as a single zip file **hw3.zip** on Gradescope under *Homework 3*. In order for the autograder to run, make sure the zip file contains **all** the .py and .ipynb files, not a folder with these files. The programming part constitutes 60% of the grade for this homework. You also need to answer the questions denoted by **WU#** (and a kitten) in this notebook which are the other 40% of your homework grade. There are also up to 25% of extra credit questions denoted by **WU-EC1**, **WU-EC3**, and **WU-EC3**. When you are done, you should export **hw3.ipynb** with your answers as a PDF file **hw3WrittenPart.pdf**, upload the PDF file to Gradescope under *Homework 3 - Written Part*, and **tag each question** on Gradescope. Questions that are not tagged will not be graded.\n",
    "\n",
    "The simplest and recommended way to export your python notebook is to select File -> Print Preview (this appears on the notebook, right under the Jupyter logo), then use the browser to print as PDF (e.g., on Chrome this appears under File->Print...->Destination \"Save as PDF\"). Make sure you double check your final PDF to make sure it's not missing any pieces before submitting your final version!\n",
    "\n",
    "Your entire homework will be considered late if any of these parts are submitted late. \n",
    "\n",
    "#### Autograding\n",
    "\n",
    "Your code will be autograded for technical correctness. Please **do\n",
    "not** change the names of any provided functions or classes within the\n",
    "code, or you will wreak havoc on the autograder. We have provided two simple test cases that you can try your code on, see ``run_tests_sample.py``. As usual, you should create more test cases to make sure your code runs correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Autoreload "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, let's import a jupyter notebook extension called [`autoreload`](https://ipython.org/ipython-doc/3/config/extensions/autoreload.html) which would automatically reload changes to external files that you edit.\n",
    "If you change something in a file and the changes are not reflected even after an autoreload, you may have to restart your jupyter notebook kernel (Kernel -> Restart).\n",
    "\n",
    "A manual alternative to `autoreload` is to reload a particular file using `importlib`.\n",
    "\n",
    "``import importlib\n",
    "importlib.reload(dumbClassifiers)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Multiclass Classification *[30% impl, 20% writeup]*\n",
    "\n",
    "In this section, you will explore the differences between three\n",
    "multiclass-to-binary reductions: one-versus-all (OVA), all-versus-all\n",
    "(AVA), and a tree-based reduction (TREE).  The evaluation will be on different datasets from \n",
    "`datasets.py`.\n",
    "\n",
    "The classification task we'll work with is wine classification. The dataset was downloaded from allwines.com. Your job is to predict the type of wine, given the description of the wine. There are two tasks: WineData has **20** different wines, WineDataSmall is just the first five of those (sorted roughly by frequency). You can find the names of the wines both in WineData.labels as well as the file wines.names.\n",
    "\n",
    "To start out, let's import everything and train decision \"stumps\" (aka depth=1 decision trees) on the large data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training classifier for 0 versus rest\n",
      "training classifier for 1 versus rest\n",
      "training classifier for 2 versus rest\n",
      "training classifier for 3 versus rest\n",
      "training classifier for 4 versus rest\n",
      "training classifier for 5 versus rest\n",
      "training classifier for 6 versus rest\n",
      "training classifier for 7 versus rest\n",
      "training classifier for 8 versus rest\n",
      "training classifier for 9 versus rest\n",
      "training classifier for 10 versus rest\n",
      "training classifier for 11 versus rest\n",
      "training classifier for 12 versus rest\n",
      "training classifier for 13 versus rest\n",
      "training classifier for 14 versus rest\n",
      "training classifier for 15 versus rest\n",
      "training classifier for 16 versus rest\n",
      "training classifier for 17 versus rest\n",
      "training classifier for 18 versus rest\n",
      "training classifier for 19 versus rest\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2949907235621521"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import multiclass\n",
    "import util\n",
    "from datasets import *\n",
    "import importlib\n",
    "from pylab import *\n",
    "\n",
    "h = multiclass.OVA(20, lambda: DecisionTreeClassifier(max_depth=1))\n",
    "h.train(WineData.X, WineData.Y)\n",
    "P = h.predictAll(WineData.Xte)\n",
    "mean(P == WineData.Yte)\n",
    "# 0.29499072356215211"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That means 29% accuracy on this task. The most frequent class is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Cabernet-Sauvignon'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(mode(WineData.Y))\n",
    "# 1\n",
    "WineData.labels[1]\n",
    "# Cabernet-Sauvignon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if you were to always predict label 1, you would get the following accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1725417439703154"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(WineData.Yte == 1)\n",
    "# 0.17254174397031541"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So decision stumps producing a bit (12%) better accuracy than just predicting label 1. \n",
    "\n",
    "The default implementation of OVA uses decision tree confidence (probability of prediction) to weigh the votes. You can switch to zero/one predictions to see the effect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19109461966604824"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = h.predictAll(WineData.Xte, useZeroOne=True)\n",
    "mean(P == WineData.Yte)\n",
    "# 0.19109461966604824"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this is markedly worse.\n",
    "\n",
    "Switching to the smaller data set for a minute, we can train, say, depth 3 decision trees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training classifier for 0 versus rest\n",
      "training classifier for 1 versus rest\n",
      "training classifier for 2 versus rest\n",
      "training classifier for 3 versus rest\n",
      "training classifier for 4 versus rest\n",
      "0.6039387308533917\n",
      "0.40700218818380746\n"
     ]
    }
   ],
   "source": [
    "h = multiclass.OVA(5, lambda: DecisionTreeClassifier(max_depth=3))\n",
    "h.train(WineDataSmall.X, WineDataSmall.Y)\n",
    "P = h.predictAll(WineDataSmall.Xte)\n",
    "print(mean(P == WineDataSmall.Yte))\n",
    "# 0.6017505470459519\n",
    "print(mean(WineDataSmall.Yte == 1))\n",
    "# 0.407002188184"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So using depth 3 trees we get an accuracy of about 60% (this number varies a bit), versus a baseline of 41%. That's not too terrible, but not great.\n",
    "\n",
    "We can look at what this classifier is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sauvignon-Blanc\n",
      "citrus?\n",
      "-N-> lime?\n",
      "|    -N-> gooseberry?\n",
      "|    |    -N-> class -1\t(356.0 for class -1, 10.0 for class +1)\n",
      "|    |    -Y-> class +1\t(0.0 for class -1, 4.0 for class +1)\n",
      "|    -Y-> variety?\n",
      "|    |    -N-> class +1\t(1.0 for class -1, 15.0 for class +1)\n",
      "|    |    -Y-> class -1\t(2.0 for class -1, 0.0 for class +1)\n",
      "-Y-> grapefruit?\n",
      "|    -N-> flavors?\n",
      "|    |    -N-> class +1\t(4.0 for class -1, 12.0 for class +1)\n",
      "|    |    -Y-> class -1\t(11.0 for class -1, 5.0 for class +1)\n",
      "|    -Y-> extremely?\n",
      "|    |    -N-> class +1\t(0.0 for class -1, 14.0 for class +1)\n",
      "|    |    -Y-> class -1\t(1.0 for class -1, 0.0 for class +1)\n"
     ]
    }
   ],
   "source": [
    "print(WineDataSmall.labels[0])\n",
    "#'Sauvignon-Blanc'\n",
    "util.showTree(h.f[0], WineDataSmall.words)\n",
    "#citrus?\n",
    "#-N-> lime?\n",
    "#|    -N-> gooseberry?\n",
    "#|    |    -N-> class 0\t(356.0 for class 0, 10.0 for class 1)\n",
    "#|    |    -Y-> class 1\t(0.0 for class 0, 4.0 for class 1)\n",
    "#|    -Y-> apple?\n",
    "#|    |    -N-> class 1\t(1.0 for class 0, 15.0 for class 1)\n",
    "#|    |    -Y-> class 0\t(2.0 for class 0, 0.0 for class 1)\n",
    "#-Y-> grapefruit?\n",
    "#|    -N-> flavors?\n",
    "#|    |    -N-> class 1\t(4.0 for class 0, 12.0 for class 1)\n",
    "#|    |    -Y-> class 0\t(11.0 for class 0, 5.0 for class 1)\n",
    "#|    -Y-> opens?\n",
    "#|    |    -N-> class 1\t(0.0 for class 0, 14.0 for class 1)\n",
    "#|    |    -Y-> class 0\t(1.0 for class 0, 0.0 for class 1)\n",
    "\n",
    "# It's okay to get a slightly different tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should show the tree that's associated with predicting label 0 (which is stored in h.f[0]). The 1s mean \"likely to be Sauvignon-Blanc\" and the 0s mean \"likely not to be\".\n",
    "\n",
    "Now, go in and complete the AVA implementation in `multiclass.py`. Make sure you follow the corrected version of the algorithm from the class slides, not the one from the book. You should be able to train an AVA model on the small data set by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training classifier for 1 versus 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This DecisionTreeClassifier estimator requires y to be passed, but the target y is None.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-fbbb9d73fc61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulticlass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAVA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWineDataSmall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWineDataSmall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWineDataSmall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXte\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mWineDataSmall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mYte\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/grad school/UIC/CS412 Intro ML/hw3/multiclass.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;31m# Yij = j if (Y == j) else None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mXij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# +1 if it's k, -1 if it's not k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0mYij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# +1 if it's k, -1 if it's not k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXij\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYij\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    896\u001b[0m         \"\"\"\n\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    899\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mcheck_X_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             X, y = self._validate_data(X, y,\n\u001b[0m\u001b[1;32m    157\u001b[0m                                        validate_separately=(check_X_params,\n\u001b[1;32m    158\u001b[0m                                                             check_y_params))\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'requires_y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    415\u001b[0m                     \u001b[0;34mf\"This {self.__class__.__name__} estimator \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                     \u001b[0;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This DecisionTreeClassifier estimator requires y to be passed, but the target y is None."
     ]
    }
   ],
   "source": [
    "h = multiclass.AVA(5, lambda: DecisionTreeClassifier(max_depth=3))\n",
    "h.train(WineDataSmall.X, WineDataSmall.Y)\n",
    "P = h.predictAll(WineDataSmall.Xte)\n",
    "print(mean(P == WineDataSmall.Yte))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you must implement a \n",
    "tree-based reduction MCTree in `multiclass.py`. Most of train is given to you, but predict you\n",
    "must do all on your own. There is a `makeBalancedTree` function to help you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = multiclass.makeBalancedTree(range(5))\n",
    "print(t)\n",
    "# [[0 1]] [2 [3 4]]]\n",
    "print(t.isLeaf)\n",
    "# False\n",
    "print(t.getRight())\n",
    "# [2 [3 4]]\n",
    "print(t.getRight().getLeft())\n",
    "# 2\n",
    "print(t.getRight().getLeft().isLeaf)\n",
    "# True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should be able to train a MCTree model by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = multiclass.MCTree(t, lambda: DecisionTreeClassifier(max_depth=3))\n",
    "h.train(WineDataSmall.X, WineDataSmall.Y)\n",
    "P = h.predictAll(WineDataSmall.Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = multiclass.makeBalancedTree(range(5))\n",
    "h = multiclass.MCTree(t, lambda: DecisionTreeClassifier(max_depth=3))\n",
    "h.train(WineDataSmall.X, WineDataSmall.Y)\n",
    "P = h.predictAll(WineDataSmall.Xte)\n",
    "np.mean(P == WineDataSmall.Yte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/kitten.jpeg\" width=\"100px\" align=\"left\" float=\"left\"/>\n",
    "<br><br><br>\n",
    "\n",
    "## WU1 (10%):\n",
    "Answer A, B, C for both OVA and AVA.\n",
    "\n",
    "(A) Using WineDataSmall, answer the following: What words are most indicative of being Sauvignon-Blanc? Which words are most indicative of not being Cabernet-Sauvignon? What about Pinot-Grigio (label=4)? Note that indicative words describe a specific wine (not others).\n",
    "\n",
    "(B) Train depth 3 decision trees on the full WineData task (with 20 labels). What accuracy do you get? How long does this take (in seconds)? One of my least favorite wines is Shiraz -- what words are indicative of this?\n",
    "\n",
    "(C) Compare the accuracy using zero-one predictions versus using confidence on the full WineData. How much difference does it make?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WU1 CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[WU1 ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/kitten.jpeg\" width=\"100px\" align=\"left\" float=\"left\"/>\n",
    "<br><br><br>\n",
    "\n",
    "## WU2 (10%):\n",
    "Using decision trees of constant depth for each\n",
    "classifier (but you choose it as well as you can!), train AVA, OVA and\n",
    "MCTree (using balanced trees) for the WineDataSmall. Which one produces best recall and why? Answer the same for WineData."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WU2 CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[WU2 ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/kitten.jpeg\" width=\"100px\" align=\"left\" float=\"left\"/>\n",
    "<br><br><br>\n",
    "\n",
    "## WU-EC1 ExtraCredit (10%):\n",
    "Build a better tree (any way you want) other\n",
    "than the balanced binary tree. Fill in your code for this in\n",
    "`getMyTreeForWine`, which defaults to a balanced tree. It should get\n",
    "at least 5% lower absolute error to get the extra credit. Describe what you\n",
    "did.\n",
    "\n",
    "[YOUR WU-EC1 ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Gradient Descent and Linear Classification *[30% impl, 20% writeup]*\n",
    "\n",
    "To get started with linear models, we will implement a generic\n",
    "gradient descent method.  This should go in `gd.py`, which\n",
    "contains a single (short) function: `gd`. This takes five\n",
    "parameters: the function we're optimizing, it's gradient, an initial\n",
    "position, a number of iterations to run, and an initial step size.\n",
    "\n",
    "In each iteration of gradient descent, we will compute the gradient\n",
    "and take a step in that direction, with step size `eta`.  We\n",
    "will have an *adaptive* step size, where `eta` is computed\n",
    "as `stepSize` divided by the square root of the iteration\n",
    "number (counting from one).\n",
    "\n",
    "Once you have an implementation running, we can check it on a simple\n",
    "example of minimizing the function `x^2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gd\n",
    "gd.gd(lambda x: x**2, lambda x: 2*x, 10, 10, 0.2)\n",
    "#(1.0034641051795872, array([ 100.        ,   36.        ,   18.5153247 ,   10.95094653,\n",
    "#          7.00860578,    4.72540613,    3.30810578,    2.38344246,\n",
    "#          1.75697198,    1.31968118,    1.00694021]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the \"solution\" found is about 1, which is not great\n",
    "(it should be zero!), but it's better than the initial value of ten!\n",
    "If yours is going up rather than going down, you probably have a sign\n",
    "error somewhere!\n",
    "\n",
    "We can let it run longer and plot the trajectory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, trajectory = gd.gd(lambda x: x**2, lambda x: 2*x, 10, 100, 0.2)\n",
    "print(x)\n",
    "# 0.003645900464603937\n",
    "plot(trajectory)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's now found a value close to zero and you can see that the\n",
    "objective is decreasing by looking at the plot.\n",
    "\n",
    "<img src=\"data/kitten.jpeg\" width=\"100px\" align=\"left\" float=\"left\"/>\n",
    "<br><br><br>\n",
    "\n",
    "## WU3 (5%):\n",
    "Find a few values of step size where it converges and\n",
    "a few values where it diverges.  Where does the threshold seem to\n",
    "be?\n",
    "\n",
    "[Your WU3 answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/kitten.jpeg\" width=\"100px\" align=\"left\" float=\"left\"/>\n",
    "<br><br><br>\n",
    "\n",
    "## WU4 (10%):\n",
    "Come up with a *non-convex* univariate\n",
    "optimization problem.  Plot the function you're trying to minimize and\n",
    "show two runs of `gd`, one where it gets caught in a local\n",
    "minimum and one where it manages to make it to a global minimum.  (Use\n",
    "different starting points to accomplish this.)\n",
    "\n",
    "If you implemented it well, this should work in multiple dimensions,\n",
    "too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, trajectory = gd.gd(lambda x: linalg.norm(x)**2, lambda x: 2*x, array([10,5]), 100, 0.2)\n",
    "print(x)\n",
    "# array([ 0.0036459 ,  0.00182295])\n",
    "plot(trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our generic linear classifier implementation is\n",
    "in `linear.py`.  The way this works is as follows.  We have an\n",
    "interface `LossFunction` that we want to minimize.  This must\n",
    "be able to compute the loss for a pair `Y` and `Yhat`\n",
    "where, the former is the truth and the latter are the predictions.  It\n",
    "must also be able to compute a gradient when additionally given the\n",
    "data `X`.  This should be all you need for these.\n",
    "\n",
    "There are two loss function stubs: `SquaredLoss` (which is\n",
    "implemented for you!), `LogisticLoss`\n",
    "(you'll have to implement.  My suggestion is to hold off\n",
    "implementing it until you have the linear classifier\n",
    "working.\n",
    "\n",
    "The `LinearClassifier` class is a stub implemention of a\n",
    "generic linear classifier with an l2 regularizer.  It\n",
    "is *unbiased* so all you have to take care of are the weights.\n",
    "Your implementation should go in `train`, which has a handful\n",
    "of stubs.  The idea is to just pass appropriate functions\n",
    "to `gd` and have it do all the work.  See the comments inline\n",
    "in the code for more information.\n",
    " \n",
    "Once you've implemented the function evaluation and gradient, we can\n",
    "test this.  We'll begin with a very simple 2D example data set so that\n",
    "we can plot the solutions.  We'll also start with *no\n",
    "regularizer* to help you figure out where errors might be if you\n",
    "have them.  (You'll have to import `mlGraphics` to make this\n",
    "work.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import linear\n",
    "import datasets\n",
    "import mlGraphics\n",
    "import runClassifier\n",
    "f = linear.LinearClassifier({'lossFunction': linear.SquaredLoss(), 'lambda': 0, 'numIter': 100, 'stepSize': 0.5})\n",
    "runClassifier.trainTestSet(f, datasets.TwoDAxisAligned)\n",
    "# Training accuracy 0.91, test accuracy 0.86\n",
    "print(f)\n",
    "# w=array([ 2.73466371, -0.29563932])\n",
    "mlGraphics.plotLinearClassifier(f, datasets.TwoDAxisAligned.X, datasets.TwoDAxisAligned.Y)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that even though this data is clearly linearly separable,\n",
    "the *unbiased* classifier is unable to perfectly separate it.\n",
    "\n",
    "If we change the regularizer, we'll get a slightly different\n",
    "solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = linear.LinearClassifier({'lossFunction': linear.SquaredLoss(), 'lambda': 10, 'numIter': 100, 'stepSize': 0.5})\n",
    "runClassifier.trainTestSet(f, datasets.TwoDAxisAligned)\n",
    "# Training accuracy 0.9, test accuracy 0.86\n",
    "print(f)\n",
    "# w=array([ 1.30221546, -0.06764756])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the weights are *smaller*.\n",
    "\n",
    "Now, we can try different loss function.  Implement logistic loss.  Here are some simple test cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = linear.LinearClassifier({'lossFunction': linear.LogisticLoss(), 'lambda': 10, 'numIter': 100, 'stepSize': 0.5})\n",
    "runClassifier.trainTestSet(f, datasets.TwoDDiagonal)\n",
    "# Training accuracy 0.99, test accuracy 0.86\n",
    "print(f)\n",
    "# w=array([ 0.29809083,  1.01287561])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/kitten.jpeg\" width=\"100px\" align=\"left\" float=\"left\"/>\n",
    "<br><br><br>\n",
    "\n",
    "## WU5 (5%):\n",
    "For each of the loss functions, train a model on the\n",
    "binary version of the wine data (called WineDataBinary) and evaluate\n",
    "it on the test data. You should use lambda=2 in all cases. Which works\n",
    "best? For that best model, look at the learned weights. Find\n",
    "the *words* corresponding to the weights with the greatest\n",
    "positive value and those with the greatest negative value (this is\n",
    "like [LAB3]). Hint: look at WineDataBinary.words to get the id-to-word\n",
    "mapping. List the top 5 positive and top 5 negative and explain.\n",
    "\n",
    "[Your WU5 answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Classification with Many Classes *[0% -- up to 15% extra credit]*\n",
    "\n",
    "Finally, we'll do multiclass classification **using Scikit-learn** functionality. You can find the documentation here: http://scikit-learn.org/stable/modules/multiclass.html.\n",
    "\n",
    "Quiz bowl is a game in which two teams compete head-to-head to answer questions from different areas of knowledge. It lets players interrupt the reading of a question when they know the answer. The goal here is to see how well a classifier performs in predicting the `Answer` of a question when a different portion of the question is revealed.\n",
    "\n",
    "Here's an example question from the development data:\n",
    "\n",
    "*206824,dev,History,Alan Turing,\"This man and Donald Bayley created a secure voice communications machine called \"\"Delilah\"\". ||| The Chinese Room Experiment was developed by John Searle in response to one of this man's namesake tests. ||| He showed that the halting problem was undecidable. ||| He devised a bomb with Gordon Welchman that found the settings of an Enigma machine. ||| One of this man's eponymous machines which can perform any computing task is his namesake \"\"complete.\"\" Name this man, whose eponymous test is used to determine if a machine can exhibit behavior indistinguishable from that of a human.\"*\n",
    "\n",
    "The more of the question you get, the easier the problem becomes.\n",
    "\n",
    "The default code below just runs OVA and AVA on top of a linear SVM (it might take a few seconds):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from numpy import *\n",
    "import datasets\n",
    "import importlib\n",
    "\n",
    "importlib.reload(datasets)\n",
    "\n",
    "if not datasets.Quizbowl.loaded:\n",
    "    datasets.loadQuizbowl()\n",
    "\n",
    "print('\\n\\nRUNNING ON EASY DATA\\n')\n",
    "    \n",
    "print('training ova')\n",
    "X = datasets.QuizbowlSmall.X\n",
    "Y = datasets.QuizbowlSmall.Y\n",
    "ova = OneVsOneClassifier(LinearSVC(random_state=0)).fit(X, Y)\n",
    "print('predicting ova')\n",
    "ovaDevPred = ova.predict(datasets.QuizbowlSmall.Xde)\n",
    "print('error = {0}'.format(mean(ovaDevPred != datasets.QuizbowlSmall.Yde)))\n",
    "\n",
    "print('training ava')\n",
    "ava = OneVsRestClassifier(LinearSVC(random_state=0)).fit(X, Y)\n",
    "print('predicting ava')\n",
    "avaDevPred = ava.predict(datasets.QuizbowlSmall.Xde)\n",
    "print('error = {0}'.format(mean(avaDevPred != datasets.QuizbowlSmall.Yde)))\n",
    "\n",
    "print('\\n\\nRUNNING ON HARD DATA\\n')\n",
    "    \n",
    "print('training ova')\n",
    "X = datasets.QuizbowlHardSmall.X\n",
    "Y = datasets.QuizbowlHardSmall.Y\n",
    "ova = OneVsOneClassifier(LinearSVC(random_state=0)).fit(X, Y)\n",
    "print('predicting ova')\n",
    "ovaDevPred = ova.predict(datasets.QuizbowlHardSmall.Xde)\n",
    "print('error = {0}'.format(mean(ovaDevPred != datasets.QuizbowlHardSmall.Yde)))\n",
    "\n",
    "print('training ava')\n",
    "ava = OneVsRestClassifier(LinearSVC(random_state=0)).fit(X, Y)\n",
    "print('predicting ava')\n",
    "avaDevPred = ava.predict(datasets.QuizbowlHardSmall.Xde)\n",
    "print('error = {0}'.format(mean(avaDevPred != datasets.QuizbowlHardSmall.Yde)))\n",
    "\n",
    "savetxt('predictions.txt', avaDevPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you run the code above, you should see some statistics of the loaded datasets and the following error rates on two of the datasets `QuizbowlSmall` and `QuizbowlHardSmall` using OVA and AVA:\n",
    "\n",
    "```\n",
    "RUNNING ON EASY DATA\n",
    "\n",
    "training ova\n",
    "predicting ova\n",
    "error = 0.293413\n",
    "training ava\n",
    "predicting ava\n",
    "error = 0.218563\n",
    "\n",
    "\n",
    "RUNNING ON HARD DATA\n",
    "\n",
    "training ova\n",
    "predicting ova\n",
    "error = 0.595808\n",
    "training ava\n",
    "predicting ava\n",
    "error = 0.553892\n",
    "```\n",
    "\n",
    "This is running on a shrunken version of the data (that only contains answers that occur at least 20 times in the data).\n",
    "\n",
    "The first (\"easy\") version is when you get to see the entire question. The second (\"hard\") version is when you only get to use the first two sentences. It's clearly significantly harder to answer!\n",
    "\n",
    "<img src=\"data/kitten.jpeg\" width=\"100px\" align=\"left\" float=\"left\"/>\n",
    "<br><br><br>\n",
    "\n",
    "## WU-EC2 (5%):\n",
    "\n",
    "Your task is to achieve the lowest possible error on the development set for `QuizbowlSmall` and `QuizbowlHardSmall`. You will get 5% extra credit for getting lower error (by at least absolute 1%) on *either* dataset than the errors presented above (21.86% for `QuizbowlSmall` and 55.39% for `QuizbowlHardSmall`). \n",
    "\n",
    "You're free to use the training data in any way you want, but you must include your code in `quizbowl.py`, submit your predictions file(s), and a writeup here that says what you did, in order to receive the extra credit. The script `quizbowl.py` includes a command in the last line that saves predictions to a text file `predictions.txt`. You need to edit this line to rename the file to either `predictionsQuizbowlSmall.txt` or `predictionsQuizbowlHardSmall.txt` dependent on the dataset: that's what you upload for the EC. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[YOUR WU-EC2 WRITEUP HERE] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/kitten.jpeg\" width=\"100px\" align=\"left\" float=\"left\"/>\n",
    "<br><br><br>\n",
    "\n",
    "## WU-EC3 (up to 10%):\n",
    "\n",
    "\n",
    "Additionally, you can get extra credit for providing the lowest-error solution on the full versions of the easy and hard problems, `Quizbowl` and `QuizbowlHard` in comparison to your classmates' solutions. There will be two separate (hidden) leaderboards for the two respective datasets. You will receive 5% if your solution is the best for the respective dataset (first place), 3% for second place and 1% for third. You are welcome to compete in both leaderboards which lets you earn up to 10% (5 + 5) extra credits for securing first place in both. We will reveal the top three scores for each dataset after the submission period is over. Note that this problem is much harder due to the larger number of class labels. A simple majority label classifier has an error of 99.89%.\n",
    "\n",
    "You're free to use the training data in any way you want, but you must include your code in `quizbowl.py`, submit your predictions file(s) (`predictionsQuizbowl.txt` and/or `predictionsQuizbowlHard.txt`), and a writeup here that says what you did, in order to receive the extra credit.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[YOUR WU-EC3 WRITEUP HERE] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
