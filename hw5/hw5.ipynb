{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Homework 5: Mini-project**\n",
    "\n",
    "**CS 412 Introduction to Machine Learning, Spring 2021 University of Illinois at Chicago**\n",
    "\n",
    "**Due: April 29, 2021, 11:59pm**\n",
    "\n",
    "*According to the Academic Integrity Policy of this course, all work submitted for grading must be done individually. While we encourage you to talk to your peers and learn from them, this interaction must be superficial with regards to all work submitted for grading. This means you cannot work in teams, you cannot work side-by-side, you cannot submit someone else’s work (partial or complete) as your own. In particular, note that you are guilty of academic dishonesty if you extend or receive any kind of unauthorized assistance. Absolutely no transfer of program code between students is permitted (paper or electronic), and you may not solicit code from family, friends, or online forums. Other examples of academic dishonesty include emailing your program to another student, copying-pasting code from the internet, working in a group on a homework assignment, and allowing a tutor, TA, or another individual to write an answer for you. Academic dishonesty is unacceptable, and penalties range from failure to expulsion from the university; cases are handled via the official student conduct process described at https://dos.uic.edu/community-standards/.\n",
    "This homework is an individual assignment for all graduate students. Undergraduate students are allowed to work in pairs and submit one homework assignment per pair. There will be no extra credit given to undergraduate students who choose to work alone. The pairs of students who choose to work together and submit one homework assignment together still need to abide by the Academic Integrity Policy and not share or receive help from others (except each other).*\n",
    "\n",
    "\n",
    "**Goal**\n",
    "\n",
    "Gain experience utilizing machine learning methods on a real-world dataset by utilizing concepts and algorithms you have learned in class.\n",
    "\n",
    "\n",
    "**Dataset**\n",
    "\n",
    "The dataset consists of 13,930 news articles from Vox (www.vox.com). In this dataset your goal is to classify whether an article is about “politics”. You are provided a binary label vector, where ‘y=1’ means the article is about politics category, and ‘y=0’ means it is not. Each article is represented by a 300-dimensional word2vec vector using the GoogleNews embedding. To get the embedding, a word2vec vector is retrieved for every word in the article, and the mean vector is computed over all words.\n",
    "The download link can be found here:\n",
    "https://uofi.box.com/s/w5hdeyorrvrvht1c9o42whkslv3pi808\n",
    "   \n",
    "The file you download should be a pickle file which you can load using the pickle module.\n",
    "There are four objects in the pickle file: (1) a 13,930x300 feature matrix, (2) a 13,930- dimensional label vector, (3) a 13,930-dimensional article id vector, (4) a 13,930-dimensional article link vector. You only need to use the features (1) and labels (2) for this task.\n",
    "To load the data, you can use this code stub with the .pkl file in the same directory:\n",
    "\n",
    "```python import pickle\n",
    "with open(\"vox_data.pkl\", \"rb\") as file:\n",
    "    x, y, article_ids, article_links = pickle.load(file)\n",
    "```\n",
    "    \n",
    "where x and y are the features and labels, respectively.\n",
    "This dataset is a subset of the Vox dataset available on data.world. If you are interested in the original dataset with the actual article titles, text and topics, you can find it here: https://data.world/elenadata/vox-articles. The original dataset is not necessary for this task.\n",
    "\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "For this Homework, your task is to implement two classifiers for binary classification that you have not already used in the previous homework assignments using existing python packages (e.g. sklearn, TensorFlow, etc.). Some examples include Random Forest, XGBoost, and Neural Networks. In addition, you will implement one classifier you have used in your previous homework assignments (i.e., Decision Trees, SVM, Nearest Neighbors, Perceptron) and compare the performance of your selected three classifiers. Use GridSearchCV to choose the best hyperparameters and then report on the final hyperparameters chosen for each classifier.\n",
    "Report the accuracy of your selected classifiers with these hyperparameters on the test data.\n",
    "\n",
    "\n",
    "**What to submit**\n",
    "\n",
    "Write-up & code: You will create a Jupyter notebook for implementing your chosen classifiers. In addition to the code, make sure that you describe each step in detail. Upload a PDF of your Jupyter notebook where all code is visible.\n",
    "Be sure to answer the following questions:\n",
    "(a) Which three classifiers (two new, one old) did you choose? (b) What software did you use and why did you choose it?\n",
    "(c) What are the results?\n",
    "Your assignment will be graded for completeness and correctness.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [[ 0.02149611  0.01773633  0.03006189 ... -0.02084504  0.02229265\n",
      "  -0.02980007]\n",
      " [ 0.03902273  0.03588958  0.01906366 ... -0.0136148   0.05033489\n",
      "  -0.04458755]\n",
      " [ 0.03498428  0.01380107  0.02972877 ... -0.04971654  0.06716254\n",
      "  -0.04707798]\n",
      " ...\n",
      " [ 0.02555814  0.02185948  0.04247121 ... -0.01317295  0.03737029\n",
      "  -0.02939126]\n",
      " [-0.09677465  0.08302101 -0.09659703 ... -0.0781685  -0.00586668\n",
      "   0.01836307]\n",
      " [ 0.04420679  0.04521789  0.03093789 ... -0.02244521  0.04476547\n",
      "  -0.04448839]]\n",
      "Y: [0. 0. 0. ... 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"vox_data.pkl\", \"rb\") as file:\n",
    "    x, y, article_ids, article_links = pickle.load(file)\n",
    "print(\"X: \" + str(x))\n",
    "print(\"Y: \" + str(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multi-layer Perceptron: A Neural Network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# features = x \n",
    "# labels = y\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest: Ensemble learning by using many decision trees then taking the mean\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "# X, Y = make_classification(n_samples=1000, n_features=4, n_informative=2, n_redundant=0, random_state=0, shuffle=False)\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(x, y)\n",
    "# print(clf.predict([[0, 0, 0, 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.1\n",
      "-0.13664588879579637\n"
     ]
    }
   ],
   "source": [
    "# XGBoost: Regularized Gradient Boosting\n",
    "\n",
    "import xgboost\n",
    "print(xgboost.__version__)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(XGBRegressor(objective='reg:squarederror'), x, y, scoring='neg_mean_squared_error')\n",
    "\n",
    "# root_mean_squared_error = (-scores)**0.5\n",
    "print(str(scores.mean()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
