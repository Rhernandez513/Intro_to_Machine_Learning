{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4: SVM and K-means\n",
    "\n",
    "UIC CS 412, Spring 2021\n",
    "\n",
    "*According to the Academic Integrity Policy of this course, all work submitted for grading must be done individually. While we encourage you to talk to your peers and learn from them, this interaction must be superficial with regards to all work submitted for grading. This means you cannot work in teams, you cannot work side-by-side, you cannot submit someone elseâ€™s work (partial or complete) as your own. In particular, note that you are guilty of academic dishonesty if you extend or receive any kind of unauthorized assistance. Absolutely no transfer of program code between students is permitted (paper or electronic), and you may not solicit code from family, friends, or online forums. Other examples of academic dishonesty include emailing your program to another student, copying-pasting code from the internet, working in a group on a homework assignment, and allowing a tutor, TA, or another individual to write an answer for you. Academic dishonesty is unacceptable, and penalties range from failure to expulsion from the university; cases are handled via the official student conduct process described at https://dos.uic.edu/conductforstudents.shtml.*\n",
    "\n",
    "This homework is an individual assignment for all graduate students. Undergraduate students are allowed to work in pairs and submit one homework assignment per pair. There will be no extra credit given to undergraduate students who choose to work alone. The pairs of students who choose to work together and submit one homework assignment together still need to abide by the Academic Integrity Policy and not share or receive help from others (except each other).\n",
    "\n",
    "There are two parts to this project. The first is on SVM (50%). The second is on k-means (50%). \n",
    "\n",
    "## Due Date\n",
    "\n",
    "This assignment is due at 11:59pm Tuesday, April 13th. \n",
    "\n",
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Project-4:-SVM-and-K-means\" data-toc-modified-id=\"Project-4:-SVM-and-K-means-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Project 4: SVM and K-means</a></span><ul class=\"toc-item\"><li><span><a href=\"#Due-Date\" data-toc-modified-id=\"Due-Date-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Due Date</a></span><ul class=\"toc-item\"><li><span><a href=\"#Files-You'll-Edit\" data-toc-modified-id=\"Files-You'll-Edit-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Files You'll Edit</a></span></li><li><span><a href=\"#Files-you-might-want-to-look-at\" data-toc-modified-id=\"Files-you-might-want-to-look-at-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Files you might want to look at</a></span></li><li><span><a href=\"#What-to-Submit\" data-toc-modified-id=\"What-to-Submit-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>What to Submit</a></span><ul class=\"toc-item\"><li><span><a href=\"#Autograding\" data-toc-modified-id=\"Autograding-1.1.3.1\"><span class=\"toc-item-num\">1.1.3.1&nbsp;&nbsp;</span>Autograding</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Part-0:-Autoreload\" data-toc-modified-id=\"Part-0:-Autoreload-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Part 0: Autoreload</a></span></li><li><span><a href=\"#Part-1:-SVM-[50-points]\" data-toc-modified-id=\"Part-1:-SVM-[50-points]-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Part 1: SVM [50 points]</a></span><ul class=\"toc-item\"><li><span><a href=\"#WU1-(10-points):\" data-toc-modified-id=\"WU1-(10-points):-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>WU1 (10 points):</a></span></li><li><span><a href=\"#WU2-(10-points)\" data-toc-modified-id=\"WU2-(10-points)-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>WU2 (10 points)</a></span></li><li><span><a href=\"#WU3-(10-points):\" data-toc-modified-id=\"WU3-(10-points):-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>WU3 (10 points):</a></span></li><li><span><a href=\"#WU4-(10-points):\" data-toc-modified-id=\"WU4-(10-points):-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>WU4 (10 points):</a></span></li><li><span><a href=\"#WU5-(10--points):\" data-toc-modified-id=\"WU5-(10--points):-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>WU5 (10  points):</a></span></li></ul></li><li><span><a href=\"#Part-3:-K-means-[20-points-implementation,-30-points-written-part]\" data-toc-modified-id=\"Part-3:-K-means-[20-points-implementation,-30-points-written-part]-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Part 3: K-means [20 points implementation, 30 points written part]</a></span><ul class=\"toc-item\"><li><span><a href=\"#WU6--(10-points)\" data-toc-modified-id=\"WU6--(10-points)-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>WU6  (10 points)</a></span></li><li><span><a href=\"#WU7-(10-points)\" data-toc-modified-id=\"WU7-(10-points)-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>WU7 (10 points)</a></span></li><li><span><a href=\"#WU8-(10-points)\" data-toc-modified-id=\"WU8-(10-points)-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>WU8 (10 points)</a></span></li></ul></li></ul></div>\n",
    "\n",
    "### Files You'll Edit\n",
    "\n",
    "``clustering.py``: An implementation of k-means that you need to finish.\n",
    "\n",
    "### Files you might want to look at\n",
    "  \n",
    "``svm-train.py``: A wrapper for scikit-learn's SVC class.\n",
    "\n",
    "``datasets.py``: Where a handful of test data sets are stored.\n",
    "\n",
    "``util.py``: A handful of useful utility functions: these will\n",
    "undoubtedly be helpful to you, so take a look!\n",
    "\n",
    "``drawBoundary.py``: A class for drawing decision boundaries.\n",
    "    \n",
    "``data/*``: All of the datasets we'll use.\n",
    "\n",
    "### What to Submit\n",
    "\n",
    "You will hand in **all** of the python files listed above as a single zip file **hw4.zip** on \n",
    "Gradescope under *Homework 4 - Programming Part*.  The programming part constitutes 20% of the grade for this \n",
    "homework. You also need to answer the questions denoted by **WU#** (and a kitten) in this \n",
    "notebook which are the other 80% of the homework grade. When you are done, you should \n",
    "export **hw4.ipynb** with your answers as a PDF file **hw4WrittenPart.pdf**, upload the \n",
    "PDF file to Gradescope under *Homework 4 - Written Part*, and tag each question on Gradescope. \n",
    "\n",
    "Your entire homework will be considered late if any of these parts are submitted late. \n",
    "\n",
    "The simplest and recommended way to export your python notebook is to select File -> Print Preview (this appears on the notebook, right under the Jupyter logo), then use the browser to print as PDF (e.g., on Chrome this appears under File->Print...->Destination \"Save as PDF\"). Make sure you double check your final PDF to make sure it's not missing any pieces before submitting your final version!\n",
    "\n",
    "**After you submit your PDF file, be sure to select the pages for each question or your answer will not be graded**\n",
    "\n",
    "#### Autograding\n",
    "\n",
    "Your code will be autograded for technical correctness. Please **do\n",
    "not** change the names of any provided functions or classes within the\n",
    "code, or you will wreak havoc on the autograder. We have provided two simple test cases that you can try your code on, see ``run_tests_simple.py``. As usual, you should create more test cases to make sure your code runs correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, let's import a jupyter notebook extension called [`autoreload`](https://ipython.org/ipython-doc/3/config/extensions/autoreload.html) which would automatically reload changes to external files that you edit.\n",
    "\n",
    "**If you change something in a file and the changes are not reflected even after an autoreload, you may have to restart your jupyter notebook kernel (Kernel -> Restart).**\n",
    "\n",
    "A manual alternative to `autoreload` is to reload a particular file using `importlib`.\n",
    "\n",
    "``import importlib\n",
    "importlib.reload(dumbClassifiers)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T22:03:56.958739Z",
     "start_time": "2021-03-08T22:03:56.894279Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: SVM [50 points]\n",
    "\n",
    "Here, we'll play around with SVMs and kernels to get a sense of what they are actually doing. We will use sklearn's SVC library for it.\n",
    "\n",
    "Let's start by training a simple linear SVM: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import svmtrain, drawBoundary, importlib\n",
    "importlib.reload(svmtrain)\n",
    "\n",
    "model = svmtrain.SVMWrapper(['-t', '0', '-c', 100, 'data0', 'data0.model'])\n",
    "model.train()\n",
    "c = drawBoundary.Boundary('data0')\n",
    "c.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This invocation of svm-train says:\n",
    "\n",
    "    -t 0    -- use a linear kernel\n",
    "    -c 100  -- set \"C\" = 100, which means \"overfit a lot\"\n",
    "\n",
    "This is an easily separable dataset, which is reflected by the small\n",
    "number of support vectors. In the plot, the SVs are drawn big (and are\n",
    "on the margin, the dashed line one unit away from the decision\n",
    "boundary, the solid line).\n",
    "\n",
    "<img src=\"kitten.jpeg\" width=\"100px\" align=\"left\" float=\"left\"/>\n",
    "<br><br><br>\n",
    "\n",
    "## WU1 (10 points):\n",
    "\n",
    "You should have found that it takes 3 support\n",
    "vectors. Could you have fewer (eg., 2) support vectors here? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[your WU1 answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although it's unnecessary, we can also train a polynomial SVM with\n",
    "degree 10 (for instance), with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svmtrain.SVMWrapper(['-t', '1', '-r', '1', '-d', 10, '-c', 100, 'data0', 'data0.model'])\n",
    "model.train()\n",
    "c = drawBoundary.Boundary('data0')\n",
    "c.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This says:\n",
    "\n",
    "    -t 1      -- use a polynomial kernel\n",
    "    -r 1      -- use (1 + u*v)^degree, where \"r\" is the \"1\"\n",
    "    -d 10     -- tenth degree\n",
    "\n",
    "You'll see that you get a curved decision boundary, though of course\n",
    "this is somewhat overkill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svmtrain.SVMWrapper(['-t', '2', '-c', 100, 'data0', 'data0.model'])\n",
    "model.train()\n",
    "c = drawBoundary.Boundary('data0')\n",
    "c.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Here, `-t 2` means RBF and `-g 1` means gamma=1)\n",
    "\n",
    "Again, this is overkill. But we can try to understand RBF kernels a\n",
    "bit better by \"turning up\" the gamma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svmtrain.SVMWrapper(['-t', '2', '-c', 100, '-g', 100, 'data0', 'data0.model'])\n",
    "model.train()\n",
    "c = drawBoundary.Boundary('data0')\n",
    "c.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A gamma of 100 means that you have to be *really* close to a point to\n",
    "have a kernel value that's non-zero.\n",
    "\n",
    "<img src=\"kitten.jpeg\" width=\"100px\" align=\"left\" float=\"left\"/>\n",
    "<br><br><br>\n",
    "\n",
    "## WU2 (10 points)\n",
    "(a) Why do you get these little blobs? \n",
    "\n",
    "(b) How high do you have to turn gamma up in order to get a little decision boundary around\n",
    "   each blue example?\n",
    "   \n",
    "(c) What is the lowest gamma has to be such that each point is a support vector?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T22:32:11.855037Z",
     "start_time": "2021-03-08T22:32:11.815644Z"
    }
   },
   "outputs": [],
   "source": [
    "# [your WU2 code here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[your WU2 answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now switch to a more complex dataset. We'll begin by failing\n",
    "with a linear model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svmtrain.SVMWrapper(['-t', '0', '-c', 100, 'data1', 'data1.model'])\n",
    "model.train()\n",
    "c = drawBoundary.Boundary('data1')\n",
    "c.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this data fails horribly.\n",
    "\n",
    "<img src=\"kitten.jpeg\" width=\"100px\" align=\"left\" float=\"left\"/>\n",
    "<br><br><br>\n",
    "\n",
    "## WU3 (10 points): \n",
    "There are a lot of red support vectors on the blue side\n",
    "   of the decision boundary. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[your WU3 answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"kitten.jpeg\" width=\"100px\" align=\"left\" float=\"left\"/>\n",
    "<br><br><br>\n",
    "\n",
    "## WU4 (10 points):\n",
    "\n",
    "(a) Using this dataset (data1) train an SVM using a polynomial kernel based on the previous examples. Can you get better mileage out of polynomial kernels on this dataset?\n",
    "\n",
    "(b) Based on this data and the results using the polynomial kernel, is the 0/1 loss on the training data zero? Is the hinge loss on the training data zero? Why? (note you do not have to compute the exact loss, an explanation is sufficient)\n",
    "\n",
    "(c) Try different values of \"C\" for the polynomial kernel. How does the decision boundary change for low values of C and high values of C? Does the 0/1 loss or hinge loss on the training data change at all?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [your WU4 code here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[your WU4 answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"kitten.jpeg\" width=\"100px\" align=\"left\" float=\"left\"/>\n",
    "<br><br><br>\n",
    "\n",
    "## WU5 (10  points):\n",
    "Train an RBF kernel on this data. What's the smallest gamma for which you can get a loss of zero on the training data for: \n",
    "   \n",
    "(a) the 0/1 loss \n",
    "\n",
    "(b) the hinge loss \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [your WU5 code here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[your WU5 answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: K-means [20 points implementation, 30 points written part]\n",
    "\n",
    "Your second task is to implement the furthest first heuristic for\n",
    "kmeans clustering in `clustering.py`.\n",
    "\n",
    "We'll now quickly run through some basic experiments with k-means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clustering, datasets\n",
    "\n",
    "mu0 = clustering.initialize_clusters(datasets.X2d, 2, 'determ')\n",
    "(mu,z,obj) = clustering.kmeans(datasets.X2d, mu0)\n",
    "print(mu)\n",
    "#array([[ 2.31287961,  1.51333813],\n",
    "#       [-2.13455999, -2.15661017]])\n",
    "print(z)\n",
    "#array([0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
    "#       1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1])\n",
    "print(obj)\n",
    "#array([ 1.91484251,  1.91484251])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint:** While running, this will plot the results.  If you want\n",
    "to turn that off, comment out the obvious line in the `kmeans`\n",
    "function.  \n",
    "\n",
    "You can also play with another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu0 = clustering.initialize_clusters(datasets.X2d2, 4, 'determ')\n",
    "(mu,z,obj) = clustering.kmeans(datasets.X2d2, mu0)\n",
    "#Iteration 0, objective=5.84574\n",
    "#Iteration 1, objective=4.3797\n",
    "#Iteration 2, objective=3.06938\n",
    "#Iteration 3, objective=2.45218\n",
    "#Iteration 4, objective=2.34795\n",
    "#Iteration 5, objective=2.34795\n",
    "print(mu)\n",
    "#array([[ 3.06150611, -1.07977065],\n",
    "#       [-3.92433223,  1.99052827],\n",
    "#       [ 0.87252863,  4.63384851],\n",
    "#       [-3.17087245, -4.10528255]])\n",
    "print(z)\n",
    "# a large array\n",
    "print(obj)\n",
    "# array([ 5.84574233,  4.37970445,  3.06937814,  2.45218374,  2.34795137,\n",
    "#        2.34795137])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run a test on dispalying digit cluster centers using random initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "importlib.reload(clustering)\n",
    "from pylab import *\n",
    "\n",
    "(X,Y) = datasets.loadDigits()\n",
    "mu0 = clustering.initialize_clusters(X, 10, 'random')\n",
    "(mu,z,obj) = clustering.kmeans(X, mu0, doPlot=False)\n",
    "plot(obj)\n",
    "show(block=False)\n",
    "util.drawDigits(mu, arange(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've implemented the furthest first heuristic (ffh), you can do a test by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(clustering)\n",
    "import numpy as np\n",
    "\n",
    "finalObj = []\n",
    "for rep in range(10):\n",
    "    np.random.seed(1234 + rep)\n",
    "    mu0 = clustering.initialize_clusters(X, 10, 'ffh')\n",
    "    (mu,z,obj) = clustering.kmeans(X, mu0, doPlot=False)\n",
    "    finalObj.append(obj[-1])\n",
    "#(lots of output)\n",
    "\n",
    "np.mean(finalObj)\n",
    "#0.44031610993896342"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may take a few seconds to run. \n",
    "\n",
    "Note: we are running kmeans multiple times and taking the mean to provide a way to rougly cross-check your outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"kitten.jpeg\" width=\"100px\" align=\"left\" float=\"left\"/>\n",
    "<br><br><br>\n",
    "\n",
    "## WU6  (10 points)\n",
    "Run kmeans with ffh. How many iterations does it seem to\n",
    "take for kmeans to converge using ffh?  Do the resulting cluster means\n",
    "look like digits for most of these runs?  Pick the \"best\" run (i.e.,\n",
    "the one with the lowest final objective) and plot the digits (include\n",
    "the plot in the writeup).  How many of the digits 0-9 are represented?\n",
    "Which ones are missing?  Try both with ffh and with random\n",
    "initialization: how many iterations does it take for kmeans to\n",
    "converge (on average) for each setting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [your WU6 code here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[your WU6 answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"kitten.jpeg\" width=\"100px\" align=\"left\" float=\"left\"/>\n",
    "<br><br><br>\n",
    "\n",
    "## WU7 (10 points)\n",
    "Repeat WU6, but for k=20.  Pick the best of 5 runs, and\n",
    "plot the digits.  Are you able to see all digits here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [your WU7 code here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[your WU7 answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, implement the kmeans++ (km++) heuristic. Here is some output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(clustering)\n",
    "\n",
    "finalObj = []\n",
    "for rep in range(20):\n",
    "    np.random.seed(1234 + rep)\n",
    "    mu0 = clustering.initialize_clusters(X, 10, 'km++')\n",
    "    (mu,z,obj) = clustering.kmeans(X, mu0, doPlot=False)\n",
    "    finalObj.append(obj[-1])\n",
    "#(lots of output)\n",
    "\n",
    "np.mean(finalObj)\n",
    "#0.4392510535744174"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"kitten.jpeg\" width=\"100px\" align=\"left\" float=\"left\"/>\n",
    "<br><br><br>\n",
    "\n",
    "## WU8 (10 points)\n",
    "Compare vanilla kmeans (with random initialization) to ffh to km++ for (a) \n",
    "    a small number of clusters (say, 3 or 4) and (b) a large number of clusters (say 20). \n",
    "    Do you see a big difference in performance at either end?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [your WU8 answer code]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[your WU8 answer here]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "412.5px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
